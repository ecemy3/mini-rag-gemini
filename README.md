Mini RAG Pipeline with Google Gemini 2.5 Flash

A minimal and high-impact Retrieval-Augmented Generation (RAG) pipeline built with Google Gemini 2.5 Flash, designed to help developers quickly understand and experiment with retrieval-augmented generation without relying on heavy frameworks. This project delivers an end-to-end flow — document loading, chunking, embedding generation via text-embedding-004, a lightweight JSON-based vector store, cosine similarity search, and context-grounded responses powered by Gemini. It serves as an accessible, extensible foundation for anyone looking to prototype real-world AI applications or extend the pipeline with Vertex AI, vector databases like Qdrant/Weaviate, FastAPI services, or UI layers.

✨ Features

Lightweight, framework-free RAG architecture

PDF/TXT loader and text chunking

Embeddings with text-embedding-004

JSON-based vector store

Cosine similarity semantic retrieval

Gemini 2.5 Flash context-grounded LLM responses
